{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "---\n",
    "\n",
    "## Web scraping and analysis\n",
    "\n",
    "This Jupyter notebook includes some code to get you started with web scraping. We will use a package called `BeautifulSoup` to collect the data from the web. Once you've collected your data and saved it into a local `.csv` file you should start with your analysis.\n",
    "\n",
    "### Scraping data from Skytrax\n",
    "\n",
    "If you visit [https://www.airlinequality.com] you can see that there is a lot of data there. For this task, we are only interested in reviews related to British Airways and the Airline itself.\n",
    "\n",
    "If you navigate to this link: [https://www.airlinequality.com/airline-reviews/british-airways] you will see this data. Now, we can use `Python` and `BeautifulSoup` to collect all the links to the reviews and then to collect the text data on each of the individual review links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 100 total reviews\n",
      "Scraping page 2\n",
      "   ---> 200 total reviews\n",
      "Scraping page 3\n",
      "   ---> 300 total reviews\n",
      "Scraping page 4\n",
      "   ---> 400 total reviews\n",
      "Scraping page 5\n",
      "   ---> 500 total reviews\n",
      "Scraping page 6\n",
      "   ---> 600 total reviews\n",
      "Scraping page 7\n",
      "   ---> 700 total reviews\n",
      "Scraping page 8\n",
      "   ---> 800 total reviews\n",
      "Scraping page 9\n",
      "   ---> 900 total reviews\n",
      "Scraping page 10\n",
      "   ---> 1000 total reviews\n",
      "Scraping page 11\n",
      "   ---> 1100 total reviews\n",
      "Scraping page 12\n",
      "   ---> 1200 total reviews\n",
      "Scraping page 13\n",
      "   ---> 1300 total reviews\n",
      "Scraping page 14\n",
      "   ---> 1400 total reviews\n",
      "Scraping page 15\n",
      "   ---> 1500 total reviews\n",
      "Scraping page 16\n",
      "   ---> 1600 total reviews\n",
      "Scraping page 17\n",
      "   ---> 1700 total reviews\n",
      "Scraping page 18\n",
      "   ---> 1800 total reviews\n",
      "Scraping page 19\n",
      "   ---> 1900 total reviews\n",
      "Scraping page 20\n",
      "   ---> 2000 total reviews\n",
      "Scraping page 21\n",
      "   ---> 2100 total reviews\n",
      "Scraping page 22\n",
      "   ---> 2200 total reviews\n",
      "Scraping page 23\n",
      "   ---> 2300 total reviews\n",
      "Scraping page 24\n",
      "   ---> 2400 total reviews\n",
      "Scraping page 25\n",
      "   ---> 2500 total reviews\n",
      "Scraping page 26\n",
      "   ---> 2600 total reviews\n",
      "Scraping page 27\n",
      "   ---> 2700 total reviews\n",
      "Scraping page 28\n",
      "   ---> 2800 total reviews\n",
      "Scraping page 29\n",
      "   ---> 2900 total reviews\n",
      "Scraping page 30\n",
      "   ---> 3000 total reviews\n",
      "Scraping page 31\n",
      "   ---> 3100 total reviews\n",
      "Scraping page 32\n",
      "   ---> 3200 total reviews\n",
      "Scraping page 33\n",
      "   ---> 3300 total reviews\n",
      "Scraping page 34\n",
      "   ---> 3400 total reviews\n",
      "Scraping page 35\n",
      "   ---> 3500 total reviews\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "pages = 35\n",
    "page_size = 100\n",
    "\n",
    "reviews = []\n",
    "\n",
    "# for i in range(1, pages + 1):\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "    for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "        reviews.append(para.get_text())\n",
    "    \n",
    "    print(f\"   ---> {len(reviews)} total reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅ Trip Verified | Absolutely horrible airline....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>✅ Trip Verified |  Having experienced delays a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>✅ Trip Verified | Travelled to Heathrow to Kal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Verified |  This flight failed at every le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not Verified |  Beware of British Airways and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews\n",
       "0  ✅ Trip Verified | Absolutely horrible airline....\n",
       "1  ✅ Trip Verified |  Having experienced delays a...\n",
       "2  ✅ Trip Verified | Travelled to Heathrow to Kal...\n",
       "3  Not Verified |  This flight failed at every le...\n",
       "4  Not Verified |  Beware of British Airways and ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"reviews\"] = reviews\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/Users/stella/Downloads/BritishAirways/BA/data/BA_reviews.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Now you have your dataset for this task! The loops above collected 1000 reviews by iterating through the paginated pages on the website. However, if you want to collect more data, try increasing the number of pages!\n",
    "\n",
    " The next thing that you should do is clean this data to remove any unnecessary text from each of the rows. For example, \"✅ Trip Verified\" can be removed from each row if it exists, as it's not relevant to what we want to investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅ Trip Verified | Absolutely horrible airline....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>✅ Trip Verified |  Having experienced delays a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>✅ Trip Verified | Travelled to Heathrow to Kal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Verified |  This flight failed at every le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not Verified |  Beware of British Airways and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>LHR to BOS. Day after baggage shut down but Fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>LHR-ARN. All the procedures at Heathrow termin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>LGW to AMS. Easy check-in at Gatwick with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>LHR-ATH-ATH June 2014. Both flights 1.5 hours ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>Travelled from Barbados to London Gatwick and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                reviews\n",
       "0     ✅ Trip Verified | Absolutely horrible airline....\n",
       "1     ✅ Trip Verified |  Having experienced delays a...\n",
       "2     ✅ Trip Verified | Travelled to Heathrow to Kal...\n",
       "3     Not Verified |  This flight failed at every le...\n",
       "4     Not Verified |  Beware of British Airways and ...\n",
       "...                                                 ...\n",
       "3495  LHR to BOS. Day after baggage shut down but Fi...\n",
       "3496  LHR-ARN. All the procedures at Heathrow termin...\n",
       "3497  LGW to AMS. Easy check-in at Gatwick with the ...\n",
       "3498  LHR-ATH-ATH June 2014. Both flights 1.5 hours ...\n",
       "3499  Travelled from Barbados to London Gatwick and ...\n",
       "\n",
       "[3500 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'✅ Trip Verified | Absolutely horrible airline. Communication is terrible. Last minute delays, cancellations, seat changes with no communication. App and website user experience is years behind other airlines. Seats are cramped and uncomfortable. Overpriced. Would not fly again.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect index 0\n",
    "\n",
    "df['reviews'].get(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b> Clean the dataset </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the NLTK libraries, used for semantic analysis purposes\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /Users/stella/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_data = df.reviews.str.strip(\"✅ Trip Verified |\")\n",
    "corpus =[]\n",
    "\n",
    "#loop through each review, remove punctuations, small case it, join it and add it to corpus\n",
    "for rev in reviews_data:\n",
    "    rev = re.sub('[^a-zA-Z]',' ', rev)\n",
    "    rev = rev.lower()\n",
    "    rev = rev.split()\n",
    "    rev = [lemma.lemmatize(word) for word in rev if word not in set(stopwords.words(\"english\"))]\n",
    "    rev = \" \".join(rev)\n",
    "    corpus.append(rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅ Trip Verified | Absolutely horrible airline....</td>\n",
       "      <td>absolutely horrible airline communication terr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>✅ Trip Verified |  Having experienced delays a...</td>\n",
       "      <td>experienced delay cancellation departing usa e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>✅ Trip Verified | Travelled to Heathrow to Kal...</td>\n",
       "      <td>avelled heathrow kalamata return journey day l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Verified |  This flight failed at every le...</td>\n",
       "      <td>verified flight failed every level delayed arr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not Verified |  Beware of British Airways and ...</td>\n",
       "      <td>verified beware british airway marketing make ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3495</th>\n",
       "      <td>LHR to BOS. Day after baggage shut down but Fi...</td>\n",
       "      <td>lhr bos day baggage shut first check easy secu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3496</th>\n",
       "      <td>LHR-ARN. All the procedures at Heathrow termin...</td>\n",
       "      <td>lhr arn procedure heathrow terminal breeze kin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>LGW to AMS. Easy check-in at Gatwick with the ...</td>\n",
       "      <td>lgw am easy check gatwick pod check print boar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>LHR-ATH-ATH June 2014. Both flights 1.5 hours ...</td>\n",
       "      <td>lhr ath ath june flight hour late always seems...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>Travelled from Barbados to London Gatwick and ...</td>\n",
       "      <td>avelled barbados london gatwick onwards italy ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                reviews  \\\n",
       "0     ✅ Trip Verified | Absolutely horrible airline....   \n",
       "1     ✅ Trip Verified |  Having experienced delays a...   \n",
       "2     ✅ Trip Verified | Travelled to Heathrow to Kal...   \n",
       "3     Not Verified |  This flight failed at every le...   \n",
       "4     Not Verified |  Beware of British Airways and ...   \n",
       "...                                                 ...   \n",
       "3495  LHR to BOS. Day after baggage shut down but Fi...   \n",
       "3496  LHR-ARN. All the procedures at Heathrow termin...   \n",
       "3497  LGW to AMS. Easy check-in at Gatwick with the ...   \n",
       "3498  LHR-ATH-ATH June 2014. Both flights 1.5 hours ...   \n",
       "3499  Travelled from Barbados to London Gatwick and ...   \n",
       "\n",
       "                                                 corpus  \n",
       "0     absolutely horrible airline communication terr...  \n",
       "1     experienced delay cancellation departing usa e...  \n",
       "2     avelled heathrow kalamata return journey day l...  \n",
       "3     verified flight failed every level delayed arr...  \n",
       "4     verified beware british airway marketing make ...  \n",
       "...                                                 ...  \n",
       "3495  lhr bos day baggage shut first check easy secu...  \n",
       "3496  lhr arn procedure heathrow terminal breeze kin...  \n",
       "3497  lgw am easy check gatwick pod check print boar...  \n",
       "3498  lhr ath ath june flight hour late always seems...  \n",
       "3499  avelled barbados london gatwick onwards italy ...  \n",
       "\n",
       "[3500 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add the corpus to the original dataframe\n",
    "\n",
    "df['corpus'] = corpus\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely horrible airline. Communication is ...</td>\n",
       "      <td>absolutely horrible airline communication terr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Having experienced delays and cancellations de...</td>\n",
       "      <td>experienced delay cancellation departing usa e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Travelled to Heathrow to Kalamata and return j...</td>\n",
       "      <td>avelled heathrow kalamata return journey day l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Verified |  This flight failed at every le...</td>\n",
       "      <td>verified flight failed every level delayed arr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not Verified |  Beware of British Airways and ...</td>\n",
       "      <td>verified beware british airway marketing make ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I flew from Cairo to Heathrow on what they cal...</td>\n",
       "      <td>flew cairo heathrow call euro club class cramp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Not Verified | I flew with numerous airlines, ...</td>\n",
       "      <td>verified flew numerous airline gotta admit bri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We were traveling as a family (5 people). Beca...</td>\n",
       "      <td>traveling family people accident airport arriv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  \\\n",
       "0  Absolutely horrible airline. Communication is ...   \n",
       "1  Having experienced delays and cancellations de...   \n",
       "2  Travelled to Heathrow to Kalamata and return j...   \n",
       "3  Not Verified |  This flight failed at every le...   \n",
       "4  Not Verified |  Beware of British Airways and ...   \n",
       "5  I flew from Cairo to Heathrow on what they cal...   \n",
       "6  Not Verified | I flew with numerous airlines, ...   \n",
       "7  We were traveling as a family (5 people). Beca...   \n",
       "\n",
       "                                              corpus  \n",
       "0  absolutely horrible airline communication terr...  \n",
       "1  experienced delay cancellation departing usa e...  \n",
       "2  avelled heathrow kalamata return journey day l...  \n",
       "3  verified flight failed every level delayed arr...  \n",
       "4  verified beware british airway marketing make ...  \n",
       "5  flew cairo heathrow call euro club class cramp...  \n",
       "6  verified flew numerous airline gotta admit bri...  \n",
       "7  traveling family people accident airport arriv...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing unwanted text(first text preprocessing)\n",
    "df.replace(re.compile(r'\\s*✅ Trip Verified \\|\\s*'), '', inplace=True)\n",
    "\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaned data \n",
    "\n",
    "df.to_csv(\"data/BA_reviews_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f7924c4c56b083e0e50eadfe7ef592a7a8ef70df33a0047f82280e6be1afe15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
